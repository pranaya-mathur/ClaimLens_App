#!/usr/bin/env python3
"""
Redis Cache Diagnostic Script

Tests:
1. Redis connection
2. Cache read/write operations
3. API cache endpoints
4. Performance benchmarks
"""

import sys
import time
import requests
from loguru import logger

# Configure logger
logger.remove()
logger.add(sys.stdout, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}")


API_BASE_URL = "http://localhost:8000"


def test_redis_connection():
    """Test Redis connection via API"""
    logger.info("üîç Testing Redis connection...")
    try:
        response = requests.get(f"{API_BASE_URL}/api/cache/health", timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            health = data.get("health", {})
            
            if health.get("connected"):
                logger.success(f"‚úÖ Redis connected: {health.get('version', 'unknown')}")
                logger.info(f"   - Memory used: {health.get('used_memory_human', 'N/A')}")
                logger.info(f"   - Clients: {health.get('connected_clients', 0)}")
                logger.info(f"   - Uptime: {health.get('uptime_in_seconds', 0)}s")
                return True
            else:
                logger.warning("‚ö†Ô∏è Redis not connected")
                logger.info("   - App will work without cache (slower)")
                return False
        else:
            logger.error(f"‚ùå API health check failed: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        logger.error("‚ùå Cannot connect to API. Is it running?")
        logger.info("üëâ Start API: python -m uvicorn api.main:app --reload")
        return False
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        return False


def test_cache_operations():
    """Test cache read/write via API"""
    logger.info("üîç Testing cache operations...")
    try:
        response = requests.get(f"{API_BASE_URL}/api/cache/test", timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get("status") == "success":
                logger.success("‚úÖ Cache read/write working")
                return True
            elif data.get("status") == "disabled":
                logger.warning("‚ö†Ô∏è Cache disabled (Redis not available)")
                return False
            else:
                logger.error(f"‚ùå Cache test failed: {data.get('message')}")
                return False
        else:
            logger.error(f"‚ùå Cache test endpoint failed: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        return False


def test_cache_stats():
    """Get cache statistics"""
    logger.info("üîç Fetching cache stats...")
    try:
        response = requests.get(f"{API_BASE_URL}/api/cache/stats", timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get("enabled"):
                logger.success("‚úÖ Cache stats retrieved")
                logger.info(f"   - Status: {data.get('status')}")
                logger.info(f"   - Total commands: {data.get('total_commands', 0):,}")
                logger.info(f"   - Memory: {data.get('memory_used', 'N/A')}")
                return True
            else:
                logger.warning("‚ö†Ô∏è Cache not enabled")
                return False
        else:
            logger.error(f"‚ùå Stats endpoint failed: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        return False


def benchmark_cache_performance():
    """Benchmark cache performance"""
    logger.info("üîç Benchmarking cache performance...")
    
    # Check if Redis is available first
    health_response = requests.get(f"{API_BASE_URL}/api/cache/health", timeout=5)
    if not health_response.json().get("health", {}).get("connected"):
        logger.warning("‚ö†Ô∏è Skipping benchmark (Redis not connected)")
        return False
    
    try:
        # Measure cache test response time
        start = time.time()
        response = requests.get(f"{API_BASE_URL}/api/cache/test", timeout=5)
        elapsed = (time.time() - start) * 1000  # Convert to ms
        
        if response.status_code == 200:
            logger.success(f"‚úÖ Cache operation: {elapsed:.2f}ms")
            
            if elapsed < 50:
                logger.success("   üöÄ Excellent performance!")
            elif elapsed < 100:
                logger.info("   ‚úÖ Good performance")
            else:
                logger.warning("   ‚ö†Ô∏è Slower than expected")
            
            return True
        else:
            logger.error("‚ùå Benchmark failed")
            return False
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        return False


def test_api_root():
    """Test API root endpoint"""
    logger.info("üîç Testing API root endpoint...")
    try:
        response = requests.get(API_BASE_URL, timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            
            # Check if cache endpoint is listed
            if "cache" in data.get("endpoints", {}):
                logger.success("‚úÖ Cache endpoints registered in API")
                return True
            else:
                logger.warning("‚ö†Ô∏è Cache endpoints not found in root")
                return False
        else:
            logger.error(f"‚ùå API root failed: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        return False


def main():
    """Run all diagnostic tests"""
    logger.info("="*60)
    logger.info("ü©∫ CLAIMLENS REDIS DIAGNOSTIC")
    logger.info("="*60)
    logger.info("")
    
    results = {
        "API Root": test_api_root(),
        "Redis Connection": test_redis_connection(),
        "Cache Operations": test_cache_operations(),
        "Cache Stats": test_cache_stats(),
        "Performance Benchmark": benchmark_cache_performance()
    }
    
    logger.info("")
    logger.info("="*60)
    logger.info("üìä DIAGNOSTIC SUMMARY")
    logger.info("="*60)
    
    passed = sum(results.values())
    total = len(results)
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        logger.info(f"  {status} - {test_name}")
    
    logger.info("")
    logger.info(f"üéØ Score: {passed}/{total} tests passed")
    
    if passed == total:
        logger.success("‚ú® ALL TESTS PASSED! Redis fully integrated! ‚ú®")
        logger.info("")
        logger.info("üöÄ Next steps:")
        logger.info("   1. Run Streamlit: streamlit run frontend/streamlit_app.py")
        logger.info("   2. Test claim analysis (should be 2x faster with cache)")
        logger.info("   3. Check cache stats: curl http://localhost:8000/api/cache/stats")
        return 0
    elif passed >= 3:
        logger.warning("‚ö†Ô∏è Some tests failed, but core functionality works")
        return 0
    else:
        logger.error("‚ùå Multiple failures detected. Check API and Redis.")
        logger.info("")
        logger.info("üîß Troubleshooting:")
        logger.info("   1. Start Redis: docker-compose up redis -d")
        logger.info("   2. Start API: python -m uvicorn api.main:app --reload")
        logger.info("   3. Check logs for errors")
        return 1


if __name__ == "__main__":
    sys.exit(main())
